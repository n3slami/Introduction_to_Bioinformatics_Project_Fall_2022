\documentclass[12pt,onecolumn,a4paper]{article}
\usepackage{epsfig,graphicx,subfigure,amsthm,amsmath}
\usepackage{color,xcolor}
\usepackage{fancyvrb}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{lscape}
\usepackage{booktabs}
\usepackage{xepersian}
\settextfont[Scale=1.0]{Roya}
\setlatintextfont[Scale=1]{Times New Roman}

\begin{document}

\begin{titlepage}
\title{پروژه‌ی مقدمه‌ای بر بیوانفورماتیک \\ فاز اول} 
\author{مهدی قیدی - 98105976 \\ امید آزادی - 98109667 \\ نوید اسلامی - 98100323}
\date{\today}
\maketitle
\end{titlepage}

در این فایل به پاسخ دادن هر کدام از سؤالات مطرح شده در دستور کار می‌پردازیم، و نیز روند کلی صورت گرفته برای انجام این فاز از پروژه را توصیف می‌کنیم. نمودار‌های کشیده شده همگی در پوشه‌ی \lr{Results} هستند، کد زده شده در پوشه‌ی \lr{Source}، و نیز داده‌های دریافت شده در پوشه‌ی \lr{Data} هستند.

ابتدا، برای این که با زبان \lr{R} و نیز دستگاه \lr{Microarray} آشنا شویم، تمام اعضای گروه ویدیوهای لینک شده از کلاس بیوانفورماتیک پیشرفته‌ی دکتر شریفی را نگاه کردیم. همراه با نگاه کردن این ویدیو‌ها، خود \lr{R}، \lr{RStudio} و نیز پیشنیاز‌های مورد نیاز برای کارکرد کتابخانه‌های خود را نصب کردیم. سپس، به آماده کردن داده‌ها، نوشتن کد‌های لازم و نیز نوشتن این گزارش پرداختیم. در تمام مراحل انجام این پروژه، افراد گروه مشارکت برابر داشتند.

\section{توصیف و خروجی \lr{Microarray}ها}
این ابزار، درواقع یک \lr{Chip} از سطوح کوچک و پیکسل مانندی است که هر کدام یک \lr{Probe} نام دارند. از نظر تئوری، این \lr{Probe}ها مشابه توالی‌های تک رشته‌ای \lr{DNA} هستند که به سیلیکون متصل شده‌اند و در نتیجه، می‌توانند با رشته‌های \lr{cDNA} پیوند برقرار کنند. اما با توجه به این که صرفاً پیوند برقرار می‌کنند و نیز چون طول این توالی‌ها کم است، هر \lr{Probe} دقیقاً مربوط به یک ژن و یک توالی خاص نیست، بلکه می‌تواند به یک تعدادی ژن وصل شود.

این دستگاه با هدف خاص بررسی میزان بیان ژن ساخته نشده است، اما از آن در این زمینه به خوبی می‌توان بهره برد. برای بررسی میزان بیان ژن، رویکرد این است که اول از \lr{DNA} اولیه‌ی خود در سلول‌های مد نظر، \lr{RNA} بسازیم و سپس از روی این \lr{RNA}‌ها که می‌توانیم آن‌ها را به دست آوریم، \lr{cDNA} بسازیم. از این \lr{cDNA}ها، بعد از این که خردشان کردیم، می‌توانیم استفاده کنیم و آن‌ها را به \lr{Probe}های خود وصل کنیم. (دو روش برای خرد کردن این \lr{cDNA}ها داریم، که یکی با تکان دادن معمولی و شدید رخ می‌دهد، و دیگری با استفاده از \lr{Sonication} است. در هر دوی این روش‌ها، چون تعداد قطعات زیاد است، از جاهای تصادفی خرد می‌شوند.)

اما قبل از این که این \lr{cDNA} را به چیپ اضافه کنیم، آن را باید با استفاده از یک رنگ فلورسانت رنگ کنیم. سپس، این مخلوط را رنگ می‌کنیم تا دو رشته‌ی \lr{cDNA} از هم جدا شوند و سپس آن را روی چیپ می‌ریزیم. در این حالت، هر رشته مکمل خود را روی \lr{Probe}ها پیدا می‌کند و به آن‌ها می‌چسبد. در آخر، چیپ را می‌شوریم تا اجزای \lr{cDNA}ای که جفت نشده بودند جدا شوند و چیپ تمیز شده را در یک اسکنر لیزری می‌گذاریم تا مشخص کند که کدام \lr{Probe}ها بیشتر از این \lr{cDNA}ها را به خود جذب کرده است، که با استفاده از میزان نوری که دیده می‌شود مشخص می‌شود. به این صورت، یک تخمین از میزان \lr{Expression} هر کدام از این \lr{Probe}ها خواهیم داشت، که همانطور که گفتیم، لزوماً به معنی زیاد یا کم بودن یک تک ژن نیست، بله به معنی زیاد یا کم بودن یک زیرمجموعه‌ای از ژن‌های ممکن است. (ژن‌های \lr{Isomorph} با هر \lr{Probe}.)

در نتیجه، خروجی این دستگاه صرفاً یک آرایه از میزان \lr{Expression}ها یا درواقع میزان پیوندی که هر \lr{Probe} ایجاد می‌کند خواهد بود. تبدیل این میزان نور دیده شده به عدد اما با استفاده از دستگاه‌های مخصوص آن صورت می‌گیرد. پس چون که چند نمونه را امتحان می‌کنیم، به ازای هر داده یک ستون از \lr{Expression}ها می‌گیریم و در آخر به یک ماتریس عددی می‌رسیم که باید آن را تحلیل کنیم.

\section{\lr{Quality Control of Data}}
قبل از این که به توصیف فرایندهای طی شده در این بخش بپردازیم، لازم است ذکر کنیم که داده‌ها را با استفاده از \lr{Accession Number} آن‌ها از \lr{GEO} دریافت کردیم و نیز دسته‌بندی گفته شده را نیز روی آن‌ها در ابزار \lr{GEO2R} اجرا کردیم. این دسته بندی تمام نمونه‌ها را در بر نمی‌گرفت اما، که باعث شد تصمیم بگیریم که تمام نمونه‌های دیگر را دور بریزیم و فقط از آن‌ها استفاده کنیم تا نمودار‌ها و تحلیل‌های ما ساده شود.

سپس، با کمک گرفتن از کد موجود در \lr{GEO2R}، رشته‌ی مربوط به دسته‌بندی داده‌ها را کپی کردیم و با استفاده از \lr{Level}ها، نام‌های مناسب را به هر کدام دادیم و داده‌های نامربوط را دور ریختیم. جزئیات انجام این فرایند را در متن کد ما می‌توانید مشاهده کنید، که بلافاصله بعد از لود کردن داده‌ها صورت می‌گیرد.

حال به بررسی کیفیت داده‌ها می‌پردازیم. اولین نکته‌ای که بررسی کردیم، مقدار بیشینه و کمینه‌ی داده‌ها بود، که بفهمیم در اسکیل لگاریتمی هستند یا نه. چون که مقدار بیشینه‌ی آن کمتر از 15 بود و کمینه‌ی آن بیشتر از 1، می‌فهمیم که در اسکیل لگاریتمی هستیم و نیازی به لگاریتمی کردن اسکیل داده‌ها نداریم. (این مقادیر را با چاپ کردن آن‌ها در خود کد \lr{R} بررسی کردیم. لزوم انجام این کار نیز در این بود که دوست داریم اعداد ما بیان‌گر مرتبه‌ی بزرگی باشند تا واقعاً تفاوت‌های غلطت را بتوانیم تشخیص دهیم، و نیز بتوانیم محاسبات بهتر و \lr{Stable}تری را در الگوریتم‌هایی می‌خواهیم برای تحلیل آن‌ها بزنیم داشته باشیم و دچار \lr{Overflow} نشویم. (به طور مثال، محاسبه‌ی \lr{Correlation} به مراتب دقت بالاتری خواهد داشت اگر اعداد ما خیلی بزرگ نباشند.)

در مرحله‌ی بعد، چیزی که باید بررسی می‌کردیم توزیع چارکی هر کدام از \lr{Probe}ها یا ژن‌ها در تمام سمپل‌ها ما بود. لازم است که این توزیع نرمالایز شده باشد، چون در غیر این صورت، در الگوریتم‌هایی که در ادامه می‌زنیم نمی‌توانیم مقایسه بین مقادیر \lr{Probe}ها داشته باشیم. همچنین، هر \lr{Probe} چون بایاس‌هایی در اندازه‌گیری دارد، دوست داریم که آن‌ها را هم کنار بگذاریم تا بتوانیم باز مقایسه‌های بهتری انجام دهیم بین مقادیر چند \lr{Probe}. پس با کشیدن یک \lr{Box Plot} از داده‌های هر \lr{Probe}، به نمودار موجود در فایل \lr{Boxplot.pdf} رسیدیم، که نشان می‌داد داده‌های ما از توزیع چارکی خیلی یکنواخت و خوبی پیروی می‌کنند و لازم نیست که دستی آن‌ها را \lr{Normalize} کنیم.

سپس، چون که یک سری از الگوریتم‌هایی که در ادامه می‌زنیم وابسته به صفر بودن میانگین کلی هر کدام از پارامتر‌های حاصل از \lr{Probe} هستند، (به خصوص \lr{PCA}) تصمیم گرفتیم که میانگین مقادیر هر کدام از این \lr{Probe}ها را بررسی کنیم و در صورتی که مقادیر بسیار متفاوتی داشتند، آن‌ها را صفر کنیم. توجه کنید که این صفر کردن الگوریتم‌های آینده‌ی ما را \lr{Stable}تر می‌کند و به این قابلیت را می‌دهد که خروجی‌های بهتری داشته باشیم و مثلاً \lr{PC}هایی که در \lr{PCA} به دست می‌آوریم به فیچر‌های نامفید داده‌ها وابسته نشده باشند. در همین راستا، از هر سطر که مربوط به هر کدام از \lr{Probe}های ما بود میانگین گرفتیم و حاصل را در فایل \lr{Gene{\_}Means.pdf} نمایش دادیم. همانطور که مشاهده می‌شود، واریانس به شدت زیادی برای این میانگین‌ها داریم، که باعث شد که تصمیم بگیریم همه‌ی آن‌ها را صفر کنیم. در نتیجه، با استفاده از تابع \lr{scale} این کار را انجام دادیم و حاصل را در یک جای دیگری ذخیره کردیم. نمودار میانگین‌های نهایی را نیز می‌توانید در \lr{Gene{\_}Means{\_}Zeroed.pdf} مشاهده کنید، که نشان می‌دهد که این مقادیر به شدت نزدیک به صفر شده‌اند.

به طور خاص، می‌توانیم تأثیر این فرایند را در دو فایل \lr{PCA/PCA{\_}Genes{\_}Not{\_}Zeroed.pdf} و \lr{PCA/PCA{\_}Genes.pdf} ببینیم. این دو فایل روی خود مقادیر \lr{Probe}ها \lr{PCA} زده‌اند و ابعاد آن‌ها را کاهش داده‌اند تا بتوانیم آن‌ها را در صفحه رسم کنیم. در فایل اول مشاهده می‌شود که \lr{PC1} یک واریانس به شدت بیشتری نسبت به سایر \lr{PC}ها دارد، در حالی که در فایل دوم یک توزیع واریانس نرم‌تری داریم. این به خاطر همین موضوع است که این واریانس زیاد به دلیل دور بودن میانگین‌ها و بیشینه و کمینه‌ی مقادیر \lr{Probe}ها مختلف است، که ناخواسته مقدار واریانس را زیاد می‌کند. همچنین، اگر \lr{Scatter Plot} این دو فایل را مشاهده کنیم، می‌بینیم که در فایل اول داده‌های خیلی \lr{Skewed} هستند و توزیع نرمالی که برای ما ایده‌آل هست را ندارند. اما این موضوع در فایل دوم حل شده است و تا حد خوبی یک توزیع نرمال مشاهده می‌کنیم. با این اوصاف، می‌فهمیم که این کم کردن میانگین کار ما را بهتر کرده است.

در آخر نیز، به نظر ما، لازم است که \lr{Correlation Matrix} را نیز بررسی کرد خود نمونه‌ها تا مطمئن شویم که مجموعه‌ی نمونه‌های ما \lr{Outlier} ندارد. با رسم این نمودار، متوجه می‌شویم که نمونه‌ی \lr{GSM1180835} که تقریباً با همه \lr{Correlation} منفی دارد و عملاً از همه‌ی نمونه‌های دیگر مجزا است. پس این نمونه را از داده‌های خود حذف می‌کنیم، و از \lr{Corr{\_}Heatmap.pdf} به نمودار \lr{Correlation Heatmap} جدید \lr{Corr{\_}Heatmap{\_}No{\_}Outliers.pdf} می‌رسیم.

همچنین، در \lr{Corr{\_}Heatmap.pdf} یک دسته از نمونه‌های سالم را پیدا می‌کنیم که فقط به هم شبیه هستند و از همه‌ی نمونه‌های دیگر متفاوت هستند، به دلیل مقادیر مشهود در \lr{Correlation}های آن‌ها. اما از آن‌جایی که این بخش را باید در سؤال آخر بررسی کنیم، توضیحات بیشتر آن را به بخش آخر موکول می‌کنیم.

\section{\lr{Dimension Reduction}}
کاهش دادن ابعاد داده‌های ما دو دلیل عمده دارد:
\begin{itemize}
\item در آخر دوست داریم که یک مدل و یا متر برای تشخیص سلول‌های سرطانی از سلول‌های سالم به دست آوریم. اما چون مجموعه‌ی داده‌ی ما در مقابل مجموعه‌ی \lr{Feature}های ما خیلی کوچک است، لازم است که تعداد فیچر‌ها را کم کنیم که پیچیدگی مدل نهایی ما نیز کم شود و از خطر رخ دادن مشکلاتی همچون \lr{Overfitting} دوری کنیم. همیچنن، با کم کردن این تعداد فیچر‌ها، می‌توانیم واقعاً متر مهم را به دست آوریم و متر‌ها و پارامتر‌هایی که اهمیت کمی دارند را دور بریزیم.
\item همچنین، دوست داریم که بتوانیم داده‌های خود را نمایش دهیم و از روی شکل آن‌ها در مورد صحت نمونه برداری و نیز نتیجه‌گیری‌ها، نظر دهیم. به طور مثال، انتظار داریم که نمونه‌های سرطانی تا حد خوبی پخش باشند، چون این موضوع از نظر مباحث \lr{Epigenics} برقرار باید باشد.
\end{itemize}

در نتیجه، با این دو هدف، سراغ آزمایش کردن روش‌های مختلف کاهش بعد می‌رویم. هر کدام از این روش‌ها را در زیر توصیف می‌کنیم و نتایج آن‌ها را نقد می‌کنیم.

\subsection{\lr{PCA}}
این روش سعی می‌کند به صورت خطی داده‌ها را در یک فضای کوچک‌تر طوی تصویر کند که واریانس‌های داده‌های \lr{Preserve} شوند. در این روش، اگر بعد نمونه‌ها را کم کنیم و نمودار توزیع آن‌ها را در فایل \lr{PCA/PCA{\_}Samples.pdf} رسم کنیم، می‌بینیم که یک سری از داده‌های سالم به خوبی از داده‌های سرطانی تفکیک می‌شوند، اما یک سری نیز در خیلی نزدیکی آن‌ها قرار می‌گیرند. این \lr{Margin} کم می‌تواند باعث شود که مدلی که در آخر برای \lr{Classification} استفاده کنیم خوب عمل نکند و دوست داریم که چنین حالتی نداشته باشیم و واقعا \lr{Cluster}هایی دور از هم داشته باشیم.

\subsection{\lr{MDS}}
این روش سعی می‌کند که داده‌ها را در فضای با بعد کمتر طوری بچیند که ماتریس فواصل دو به دوی نمونه‌های ما تا جای ممکن مشابه حالت اولیه‌ی \lr{High-Dimensional} باشد. این الگوریتم دو نوع \lr{Metric} و \lr{Non-Metric} دارد، که در این مجموعه‌ی نمونه‌ی خاص، دقیقاً مشابه هم عمل می‌کنند و یک خروجی را به ما می‌دهند. همچنین، اگر کمی بررسی کنیم، می‌بینیم که خروجی حاصل از این الگوریتم عملاً همان خروجی حاصل از \lr{PCA} است که صرفاً \lr{Flip} شده است. در نتیجه، همه‌ی بدی و خوبی‌های آن را نیز دارد. نمودار‌های مربوط به خروجی‌های این الگوریتم فایل‌های \lr{MDS/Metric{\_}MDS{\_}Samples.pdf} و \lr{MDS/Non-Metric{\_}MDS{\_}Samples.pdf} هستند.

\subsection{\lr{t-SNE}}
این الگوریتم اما با ورودی گرفتن یک \lr{Perplexity}، مکان مناسب داده‌ها را در دو بعد برای ما مشخص می‌کند. همانطور که در فایل خروجی \lr{t-SNE/t-SNE{\_}Samples.pdf} مشاهده می‌شود، این روش کاهش بعد بهترین عملکرد را دارد و در کنار داشتن خوبی‌های دو روش قبل، \lr{Margin} بزرگ‌تری برای داده‌ها ایجاد می‌کند و می‌توان از آن برای \lr{Classification} بهتر استفاده کرد.

پس چون که \lr{t-SNE} هم تفکیک‌های دسته‌های دور را به خوبی انجام می‌دهد، و چون \lr{Margin} بیشتری بین داده‌های سالم و سرطانی ایجاد می‌کند، بهتر است که از آن برای کاهش ابعاد خود استفاده کنیم. توجه کنید که اینجا نیز یکنواخت پخش شدن نمونه‌های سرطانی را به خوبی می‌توانیم مشاهده کنیم، که یکی دیگر از متر‌هایی بود که طبق تئوری اپیژنیک انتظار داشتیم. این در حالی است که همین پخش شدن در دو روش دیگر کمتر مشهود است.

\section{\lr{Correlation Heatmap}}
فیلد \lr{Source Name} مشخص می‌کند که نمونه‌ی مورد نظر از کدام سلول‌ها، محیط‌ها و یا افراد گرفته شده است. به طور مثال، سلول‌ها بیمار همگی از \lr{Source} با نام \lr{AML Patient} گرفته شده‌اند، که به این معنی است که از یک فرد بیمار آمده است. اما سلول‌های سالم از دسته‌هایی مثل \lr{T Cells}، \lr{B Cells} و غیره آمده است، که به معنی این است که از سلول‌های مختلف از افراد سالم تهیه شده‌اند.

حال، برای بررسی همبستگی بین داده‌ها، به نمودار مرسوم در فایل \lr{Corr{\_}Heatmap{\_}No{\_}Outliers.pdf} نگاه می‌کنیم. همانطور که در این نمودار دیده می‌شود، نمونه‌های سالمی که از منبع \lr{Granulocytes} هستند، همگی با هم \lr{Correlation} خوبی دارند، اما با اکثر نمونه‌های دیگر، به خصوص با نمونه‌های سرطانی، \lr{Correlation} منفی دارند. این به این معنی است که این نمونه‌ها به احتمال خوبی از یک توزیع نامرتطبی پیوری می‌کنند و می‌توانیم آن‌ها را به طور کلی از داده‌های خود حذف کنیم، چون داده‌های دیگر ما آن‌هایی هستند که واقعاً مهم است در آن‌ها \lr{Differentiator} پیدا کنیم.

سایر گروه‌ها را که بررسی کنیم، متوجه می‌شویم که منبع \lr{CD34+HSPC} از بقیه‌ی نمونه‌ها کمی همبستگی بیشتری با داده‌های سرطانی دارند، خصوصاً چون که در درختی که در این نمودار کشیده شده‌اند در فاصله‌ی کمتری قرار دارند. اما می‌توان دید که عملاً سایر گروه‌ها نیز \lr{Correlation} نابدیهی‌ای که با نمونه‌های سرطانی نیز دارند، و بهتر است که در تحلیل‌های خود آن‌ها را نیز در نظر داشته باشیم و صرفاً دسته‌ای که بالا حذف کردیم را واقعاً حذف کنیم.

لزوم انتخاب این دسته‌ی با همبستگی بالا در این است که هدف ما پیدا کردن یک متر \lr{Non-Trivial} برای جدا کردن نمونه‌های سالم و سرطانی شبیه به هم است. در نتیجه، نمونه‌هایی که دارای همبستگی بالایی هستند شباهت شایانی نیز دارند و خوب است که در تحلیل‌های خود برای پیدا کردن چنین متری، از این داده‌ها استفاده کنیم تا واقعاً بتوانیم یک \lr{Differentiator} خوب و مفید برای تشخیص سرطان پیدا کنیم. (درواقع وقت خود را برای پیدا کردن یک جداساز برای داده‌های واضحاً متفاوت دور نریزیم.)

\end{document}